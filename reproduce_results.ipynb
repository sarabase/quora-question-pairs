{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Reproduce results\n",
    "\n",
    "<div style=\"color:red; font-size:14px;\">!! Don't define functions here, import them from utils.py</div>\n",
    "\n",
    "This notebook loads the trained models from disk and shows the results obtained with them."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Imports"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "home_dir = os.environ['HOME']\n",
    "path_folder_quora = home_dir + '/Datasets/QuoraQuestionPairs'"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(os.path.join(path_folder_quora, 'quora_train_data.csv'))\n",
    "# concatenate qid1 and qid2 into a new column called \"qid\"\n",
    "qid1 = train_df[['qid1', 'question1']].rename(columns={'qid1': 'qid', 'question1': 'question'})\n",
    "qid2 = train_df[['qid2', 'question2']].rename(columns={'qid2': 'qid', 'question2': 'question'})\n",
    "qid_df = pd.concat([qid1, qid2])\n",
    "\n",
    "# drop any duplicate rows based on \"qid\" column\n",
    "qid_df = qid_df.drop_duplicates(subset=['qid'])\n",
    "\n",
    "# sort the dataframe by \"qid\"\n",
    "qid_df = qid_df.sort_values(by=['qid'])\n",
    "\n",
    "# reset the index of the dataframe\n",
    "qid_df = qid_df.reset_index(drop=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Simple Solution Evaluation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Load files related to the model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Load the saved model\n",
    "with open('model_artifacts/simple_solution/lr_model.pkl', 'rb') as file:\n",
    "    lr_model = pickle.load(file)\n",
    "with open('model_artifacts/simple_solution/X_tr_q1q2.pkl', 'rb') as file:\n",
    "    X_train = pickle.load(file)\n",
    "    X_train = scipy.sparse.csr_matrix(X_train)\n",
    "with open('model_artifacts/simple_solution/y_tr.pkl', 'rb') as file:\n",
    "    y_train = pickle.load(file)\n",
    "with open('model_artifacts/simple_solution/X_va_q1q2.pkl', 'rb') as file:\n",
    "    X_val = pickle.load(file)\n",
    "    X_val = scipy.sparse.csr_matrix(X_val)\n",
    "with open('model_artifacts/simple_solution/y_va.pkl', 'rb') as file:\n",
    "    y_val = pickle.load(file)\n",
    "with open('model_artifacts/simple_solution/X_te_q1q2.pkl', 'rb') as file:\n",
    "    X_test = pickle.load(file)\n",
    "    X_test = scipy.sparse.csr_matrix(X_test)\n",
    "with open('model_artifacts/simple_solution/y_te.pkl', 'rb') as file:\n",
    "    y_test = pickle.load(file)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Results"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print('========== TRAIN SET ==========')\n",
    "evaluate_model(lr_model, X_train, y_train)\n",
    "print('========== VALIDATION SET ==========')\n",
    "evaluate_model(lr_model, X_val, y_val)\n",
    "print('========== TEST SET ==========')\n",
    "evaluate_model(lr_model, X_test, y_test)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Improved Solution Evaluation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Load files related to the model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Load the saved model\n",
    "with open('model_artifacts/improved_solution1/xgb_model.pkl', 'rb') as file:\n",
    "    xgb_model = pickle.load(file)\n",
    "with open('model_artifacts/improved_solution1/X_tr_q1q2.pkl', 'rb') as file:\n",
    "    X_train = pickle.load(file)\n",
    "with open('model_artifacts/improved_solution1/y_tr.pkl', 'rb') as file:\n",
    "    y_train = pickle.load(file)\n",
    "with open('model_artifacts/improved_solution1/X_va_q1q2.pkl', 'rb') as file:\n",
    "    X_val = pickle.load(file)\n",
    "with open('model_artifacts/improved_solution1/y_va.pkl', 'rb') as file:\n",
    "    y_val = pickle.load(file)\n",
    "with open('model_artifacts/improved_solution1/X_te_q1q2.pkl', 'rb') as file:\n",
    "    X_test = pickle.load(file)\n",
    "with open('model_artifacts/improved_solution1/y_te.pkl', 'rb') as file:\n",
    "    y_test = pickle.load(file)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Results"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print('========== TRAIN SET ==========')\n",
    "evaluate_model(xgb_model, X_train, y_train)\n",
    "print('========== VALIDATION SET ==========')\n",
    "evaluate_model(xgb_model, X_val, y_val)\n",
    "print('========== TEST SET ==========')\n",
    "evaluate_model(xgb_model, X_test, y_test)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### See some mistakes"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "incorrect_indices, predictions = get_mistakes(xgb_model, X_test, y_test)\n",
    "\n",
    "# Show 15 random mistakes\n",
    "for i in np.random.choice(incorrect_indices, 15):\n",
    "    qid1 = X_test.iloc[i]['qid1']\n",
    "    qid2 = X_test.iloc[i]['qid2']\n",
    "    print('Question 1: {}'.format(qid_df[qid_df['qid']==qid1].question.values))\n",
    "    print('Question 2: {}'.format(qid_df[qid_df['qid']==qid2].question.values))\n",
    "    print('Predicted: {}'.format(predictions[i]))\n",
    "    print('Actual: {}'.format(y_test[i]))\n",
    "    print('------------------------------------')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
