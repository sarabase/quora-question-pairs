{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Train Models\n",
    "<div style=\"color:red; font-size:14px;\">!! Don't define functions here, import them from utils.py</div>\n",
    "\n",
    "This notebook contains the code needed to train and store models to disk.\n",
    "\n",
    "Remember that if you use a function with a random state you have to fix it to a number so that the results are reproducible."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Imports"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn import *\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "from utils import *"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Read data and split"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "home_dir = os.environ['HOME']\n",
    "path_folder_quora = home_dir + '/Datasets/QuoraQuestionPairs'"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "path_folder_quora"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(os.path.join(path_folder_quora, 'quora_train_data.csv'))\n",
    "test_df = pd.read_csv(os.path.join(path_folder_quora, 'quora_test_data.csv'))\n",
    "\n",
    "A_df, te_df = sklearn.model_selection.train_test_split(train_df,\n",
    "                                                       test_size=0.05,\n",
    "                                                       random_state=123)\n",
    "tr_df, va_df = sklearn.model_selection.train_test_split(A_df,\n",
    "                                                        test_size=0.05,\n",
    "                                                        random_state=123)\n",
    "y_tr = tr_df['is_duplicate'].values\n",
    "X_tr_df = tr_df.drop(['is_duplicate'], axis =1)\n",
    "\n",
    "y_va = va_df['is_duplicate'].values\n",
    "X_va_df = va_df.drop(['is_duplicate'], axis =1)\n",
    "\n",
    "y_te = te_df['is_duplicate'].values\n",
    "X_te_df = te_df.drop(['is_duplicate'], axis =1)\n",
    "\n",
    "print('X_tr_df.shape=',X_tr_df.shape)\n",
    "print('y_tr.shape=',y_tr.shape)\n",
    "print('X_va.shape=',X_va_df.shape)\n",
    "print('y_va_df.shape=',y_tr.shape)\n",
    "print('X_te.shape=',X_te_df.shape)\n",
    "print('y_tr_df.shape=',y_tr.shape)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Explore data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_df.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Simple Solution"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Build corpus combining all questions in a list\n",
    "all_q1 = list(X_tr_df[\"question1\"])\n",
    "all_q2 = list(X_tr_df[\"question2\"])\n",
    "all_questions = all_q1 + all_q2\n",
    "\n",
    "len(all_questions)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Cast lists as strings\n",
    "all_questions = cast_list_as_strings(all_questions)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Train and transform using Count Vectorizer\n",
    "count_vectorizer = sklearn.feature_extraction.text.CountVectorizer(ngram_range=(1,1))\n",
    "count_vectorizer.fit(all_questions)\n",
    "\n",
    "X_tr_q1q2 = get_features_from_df(X_tr_df,count_vectorizer)\n",
    "X_va_q1q2 = get_features_from_df(X_va_df,count_vectorizer)\n",
    "X_te_q1q2  = get_features_from_df(X_te_df, count_vectorizer)\n",
    "\n",
    "X_tr_q1q2.shape, tr_df.shape, X_va_q1q2.shape, va_df.shape, te_df.shape, X_te_q1q2.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Train Logistic Regression Model\n",
    "lr_model = sklearn.linear_model.LogisticRegression(solver=\"liblinear\",\n",
    "                                                   random_state=123)\n",
    "lr_model.fit(X_tr_q1q2, y_tr)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Save model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if not os.path.isdir(\"model_artifacts\"):\n",
    "    os.mkdir(\"model_artifacts\")\n",
    "\n",
    "if not os.path.isdir(\"model_artifacts/simple_solution\"):\n",
    "        os.mkdir(\"model_artifacts/simple_solution\")\n",
    "        # Save model and validation and test datasets\n",
    "        with open('model_artifacts/simple_solution/lr_model.pkl', 'wb') as file:\n",
    "            pickle.dump(lr_model, file)\n",
    "        with open('model_artifacts/simple_solution/X_tr_q1q2.pkl', 'wb') as file:\n",
    "            pickle.dump(X_tr_q1q2, file)\n",
    "        with open('model_artifacts/simple_solution/y_tr.pkl', 'wb') as file:\n",
    "            pickle.dump(y_tr, file)\n",
    "        with open('model_artifacts/simple_solution/X_va_q1q2.pkl', 'wb') as file:\n",
    "            pickle.dump(X_va_q1q2, file)\n",
    "        with open('model_artifacts/simple_solution/y_va.pkl', 'wb') as file:\n",
    "            pickle.dump(y_va, file)\n",
    "        with open('model_artifacts/simple_solution/X_te_q1q2.pkl', 'wb') as file:\n",
    "            pickle.dump(X_te_q1q2, file)\n",
    "        with open('model_artifacts/simple_solution/y_te.pkl', 'wb') as file:\n",
    "            pickle.dump(y_te, file)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
